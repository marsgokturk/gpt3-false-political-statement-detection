{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d031a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Mars Gokturk Buchholz\"\n",
    "__version__ = \"CS224u, Stanford, Winter 2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3bfde79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mmars-gokturk\u001B[0m (\u001B[33mmars-works\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from open_ai_client import LiarDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b2fd5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"###\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f45ebe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1267 entries, 0 to 1266\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   id                 1267 non-null   object\n",
      " 1   label              1267 non-null   object\n",
      " 2   statement          1267 non-null   object\n",
      " 3   subject            1267 non-null   object\n",
      " 4   speaker            1267 non-null   object\n",
      " 5   speaker_job_title  942 non-null    object\n",
      " 6   state_info         1005 non-null   object\n",
      " 7   party_affiliation  1267 non-null   object\n",
      " 8   barely_true_c      1267 non-null   int64 \n",
      " 9   half_true_c        1267 non-null   int64 \n",
      " 10  false_c            1267 non-null   int64 \n",
      " 11  mostly_true_c      1267 non-null   int64 \n",
      " 12  pantsonfire_c      1267 non-null   int64 \n",
      " 13  context            1250 non-null   object\n",
      "dtypes: int64(5), object(9)\n",
      "memory usage: 138.7+ KB\n"
     ]
    }
   ],
   "source": [
    "test_ds = LiarDataset(\"../input_data/test.tsv\", \"liar_test\")\n",
    "test_df = test_ds.get()\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb548a4e",
   "metadata": {},
   "source": [
    "For zero-shot prompt, we don't need to process the dataset. We will only use the statement column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab900bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(statement:str):    \n",
    "    p =f\"\"\"\n",
    "        Act as a research journalist doing fact-checking on the statements given by politicians. You will label each \n",
    "        statement as one of \"true, mostly-true, half-true, barely-true, false or pants-fire\". \n",
    "        Use below metric to label each statement:\n",
    "\n",
    "        If the statement is accurate and there’s nothing significant missing, then label as \"true\"\n",
    "        If the statement is accurate but needs clarification or additional information, then label as \"mostly-true\"\n",
    "        If the statement is partially accurate but leaves out important details or takes things out of context, then label as \"half-true\"\n",
    "        If the statement contains an element of truth but ignores critical facts that would give a different impression, then label as \"barely-true\"\n",
    "        If the statement is not accurate, then label as \"false\"\n",
    "        If the statement is not accurate and makes a ridiculous claim, then label as \"pants-fire\"\n",
    "\n",
    "        Use only factual data and reliable sources such as major news outlets and fact-checking organizations in the USA.\n",
    "        Provide evidence for the labels and the name, date and author of the evidence for your answer.  If you don't have any evidence, say \"I don't have any evidence\". \n",
    "        You answer should be in this format: \"Label: <statement label>, Evidence: <evidence>\"\n",
    "        ---\n",
    "        {statement}\n",
    "        \"\"\"    \n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      temperature=0.0,    \n",
    "      messages=[{\"role\": \"user\", \"content\":p }])  \n",
    " \n",
    "    \n",
    "    response_state = response[\"choices\"][0][\"finish_reason\"]\n",
    "    label = \"\"\n",
    "    evidence = \"\"\n",
    "    if response_state != \"stop\":\n",
    "        return \"invalid_response\"\n",
    "    else:\n",
    "        response_text = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        \n",
    "        if \"label\" in response_text.lower():\n",
    "            label = response_text.lower().split(\"label:\")[1].split(\"evidence\")[0].lower().strip()\n",
    "        if \"evidence\" in response_text.lower():\n",
    "            evidence = response_text.lower().split(\"evidence:\")\n",
    "            if len(evidence) > 1:\n",
    "                evidence = evidence[1].strip()\n",
    "\n",
    "        if \"pants-fire\" in label:\n",
    "            label = \"pants-fire\"\n",
    "        elif \"false\" in label:\n",
    "            label= \"false\"\n",
    "        elif \"mostly-true\" in label:\n",
    "            label= \"mostly-true\"\n",
    "        elif \"barely-true\" in label:\n",
    "            label= \"barely-true\"\n",
    "        elif \"half-true\" in label:\n",
    "            label= \"half-true\"\n",
    "        elif \"true\" in label:\n",
    "            label= \"true\" \n",
    "        else:\n",
    "            label= \"undefined\"\n",
    "            \n",
    "        return label, evidence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09a7382b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label = mostly-true, evidence = according to a report by the kaiser family foundation, medicaid spending did decline by 1.9 percent in 2012, which was the second decline in 47 years. however, the report also notes that the decline was largely due to a decrease in enrollment and utilization, rather than a decrease in spending per enrollee. (source: kaiser family foundation, \"medicaid spending and enrollment growth: fy 2012 & 2013,\" september 2014)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('mostly-true',\n",
       " 'according to a report by the kaiser family foundation, medicaid spending did decline by 1.9 percent in 2012, which was the second decline in 47 years. however, the report also notes that the decline was largely due to a decrease in enrollment and utilization, rather than a decrease in spending per enrollee. (source: kaiser family foundation, \"medicaid spending and enrollment growth: fy 2012 & 2013,\" september 2014)')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "l, e = get_completion(\"Medicaid spending declined by 1.9 percent in 2012, the second such decline in 47 years.\")\n",
    "l, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79d9799a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1267, step=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = test_df.reset_index()\n",
    "test_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0787bacc",
   "metadata": {},
   "source": [
    "## Zero-shot with prompt\n",
    "If an exception arises from the API, the data collected up to that point will be written to a file. You can then resume from where it left off by adjusting the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8698f6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1190/1190 [3:07:37<00:00,  9.46s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "idx = []\n",
    "labels = []\n",
    "evidences = []\n",
    "for i in tqdm(range(77, test_df.shape[0])):    \n",
    "    st = test_df.iloc[i][\"statement\"]\n",
    "    try:\n",
    "        label, evidence = get_completion(st)\n",
    "        idx.append(i)\n",
    "        labels.append(label)\n",
    "        evidences.append(evidence)\n",
    "        time.sleep(5)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        a = pd.DataFrame({\"idx\": idx, \"label\": labels, \"evidence\": evidences})\n",
    "        a.to_csv(f\"result_between_77_until_{i}.csv\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54df8a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1190 entries, 0 to 1189\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   idx       1190 non-null   int64 \n",
      " 1   label     1190 non-null   object\n",
      " 2   evidence  1190 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 28.0+ KB\n"
     ]
    }
   ],
   "source": [
    "b = pd.DataFrame({\"idx\": idx, \"label\": labels, \"evidence\": evidences})\n",
    "b.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4045911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 77 entries, 0 to 76\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   idx       77 non-null     int64 \n",
      " 1   label     77 non-null     object\n",
      " 2   evidence  77 non-null     object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.4+ KB\n"
     ]
    }
   ],
   "source": [
    "a = pd.read_csv(\"../output_data/result_until_77.csv\", index_col=0)\n",
    "a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ef1ba9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1267 entries, 0 to 1189\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   idx       1267 non-null   int64 \n",
      " 1   label     1267 non-null   object\n",
      " 2   evidence  1267 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 39.6+ KB\n"
     ]
    }
   ],
   "source": [
    "all_tr = pd.concat([a,b])\n",
    "all_tr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd6012e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>label</th>\n",
       "      <th>evidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>true</td>\n",
       "      <td>\"according to a report by the government accou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx label                                           evidence\n",
       "0    0  true  \"according to a report by the government accou..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tr.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a4f2cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tr = all_tr.rename(columns={\"label\": \"predicted_label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e080f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tr.to_csv(\"../output_data/all_test_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-deep",
   "language": "python",
   "name": "nlp-deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
